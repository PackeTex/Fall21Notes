\lecture{25}{Fri 22 Oct 2021 10:23}{Psuedo-Random Graphs}
\section{Psuedo-Random Graphs}
\begin{definition}[Psuedo-Random Graph]
	A \textbf{psuedo-random graph}	is a \(d\)-regular graph of order \(n\) with \(\sigma_2\left( G \right) \le \lambda\) and \(\lambda = o\left( d \right) \) . We denoted this \(\left( n, d, \lambda \right) \)
\end{definition}

Let \(G\) be a \(\left( n, n^{\frac{2}{3}}, 2n^{\frac{1}{2}} \right) \). Then, we derive some nice conditions on the hamiltonicity of \(G\).
\begin{proposition}[Expander Mixing Lemma]
	Let \(G\) be a \(d\)-regular graph of order \(n\), then for every \(X, Y \subseteq V\left( G \right) \), we find \[
		\left| e\left( X, Y \right) - \frac{d}{n} \left| X \right| \left| Y \right|  \right| \le \sigma_2\left( G \right) \sqrt{\left| X \right| \left| Y \right| }
	.\]
\end{proposition}
\begin{proof}
	Note here \(e\left( X, Y \right) \) double counts edges in the intersection \(X \cap Y\). Hence, \(e\left( X, X \right) = 2e\left( X \right) \). Then, note \(\frac{d}{n} = \frac{dn}{n^2} = \frac{e\left( G \right)}{n^2}\), the density of \(G\).\\
	Now, let \(X \subseteq M\) and define a vector \(j_{X} = \begin{pmatrix} x_1\\ \vdots\\ x_n \end{pmatrix}\) with \(x_{i} = \left \{
		\begin{array}{11}
			1, & \quad i \in X \\
			0, & \quad i\not\in X
		\end{array}
		\right.\)
		Then, note that \(\left<j_{X}, j_{X} \right> = \left| X \right|  \) and \(\left<j_{X}, j_{Y} \right> = \left| X \cap Y \right|  \).\\
		Then, letting \(X \subseteq \left[ n \right] \) to be a subsets of all numbers less than or equal to \(n\), then we see letting \(A\) be a \(\left( 0, 1 \right) \) matrix which is \(n \times n\), we have \(\left<Aj_{X}, j_{Y} \right> = e\left( Y, X \right) = e\left( X, Y \right) \). Lastly, \(\left<J_{n} j_{X}, j_{Y} \right> = \left| X \right| \left| Y \right|  \)  Defining \(B = A - \frac{s}{n^2}J_{n}\), we see \(\frac{s}{n^2} = \frac{d}{n}\), hence \(B = A - \frac{d}{n}J_{n}\). Then, note \(\left< Bj_{X}, j_{Y} \right> = e\left( X, Y \right)  - \frac{d}{n}\left| X \right| \left| Y \right| \).\\
		Hence, we have reduced the left hand side to \(\left<Bj_{X}, j_{Y} \right> \). Then, note that \(\left| \lambda_{i} \right| \le \sigma_2\left( G \right) \le \lambda\) for \(2 \le i \le n\). Then, as \(\lambda_1\left( G \right) =  \lambda_1\left( \frac{d}{n}J \right)  = d\), we see \(\lambda_{1}\left( B \right)  = 0\)  and \(\lambda_{j}\left( B \right)  = \lambda_{j}\left( A \right) \) for all \(2 \le j \le n\).Clearly
\end{proof}
